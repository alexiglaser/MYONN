{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# notebook using Julia replicating the Python notebook for Make Your Own Neural Network\n",
    "# working with the MNIST data set\n",
    "#\n",
    "# Quick aside about Julia, by default it will always print the output (or in a notebook output from the last command)\n",
    "# To stop this we place a semi-colon after the last command\n",
    "#\n",
    "# (c) Alex Glaser, 2017\n",
    "# license is GPLv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition activate(Any) in module Main at In[167]:2 overwritten at In[172]:2.\n",
      "WARNING: Method definition train(Any, Any, Any, Any, Any) in module Main at In[167]:14 overwritten at In[172]:14.\n",
      "WARNING: Method definition query(Any, Any, Any) in module Main at In[164]:41 overwritten at In[172]:46.\n"
     ]
    }
   ],
   "source": [
    "# Whilst you could create a class in Julia, this was a little bit of an advanced topic for someone taking their first steps in Julia\n",
    "# Instead we stick with functions.\n",
    "function activate(x)\n",
    "    return 1./(1+exp(-x))\n",
    "end\n",
    "function train(wih, who, lr, inputs, targets)\n",
    "    # calculate signals into hidden layer\n",
    "    # matrix multiplication in Julia is done via the \"*\" command\n",
    "    hidden_inputs = wih * inputs\n",
    "    # calculate the signals emerging from hidden layer\n",
    "    hidden_outputs = activate(hidden_inputs)\n",
    "\n",
    "    # calculate signals into final output layer\n",
    "    final_inputs = who * hidden_outputs\n",
    "    # calculate the signals emerging from final output layer\n",
    "    final_outputs = activate(final_inputs)\n",
    "\n",
    "    # output layer error is the (target - actual)\n",
    "    output_errors = targets - final_outputs\n",
    "    # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "    # In Julia transposing a matrix (or array) is done by adding a ' at the end of the variable name\n",
    "    hidden_errors = who' * output_errors\n",
    "\n",
    "    # update the weights for the links between the hidden and output layers\n",
    "    # Note in Julia, element-by-element multiplication is done by the \".*\" command\n",
    "    who += lr * (output_errors .* final_outputs .* (1.0 - final_outputs)) * hidden_outputs'\n",
    "\n",
    "    # update the weights for the links between the input and hidden layers\n",
    "    wih += lr * (hidden_errors .* hidden_outputs .* (1.0 - hidden_outputs)) * inputs'\n",
    "\n",
    "    return(wih, who)\n",
    "    \n",
    "end\n",
    "# query the neural network\n",
    "function query(wih, who, inputs)\n",
    "    # calculate signals into hidden layer\n",
    "    hidden_inputs = wih * inputs\n",
    "    # calculate the signals emerging from hidden layer\n",
    "    hidden_outputs = activate(hidden_inputs)\n",
    "\n",
    "    # calculate signals into final output layer\n",
    "    final_inputs = who * hidden_outputs\n",
    "    # calculate the signals emerging from final output layer\n",
    "    final_outputs = activate(final_inputs)\n",
    "\n",
    "    return(final_outputs)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create instance of neural network\n",
    "# As we have not created a class for the neural network each element is created individually\n",
    "inodes = input_nodes\n",
    "hnodes = hidden_nodes\n",
    "onodes = output_nodes\n",
    "lr = learning_rate\n",
    "# As randn generates numbers from a standard normal distribution we have to multiply by the standard deviation \n",
    "wih = randn(hnodes,inodes) * hnodes^(-0.5)\n",
    "who = randn(onodes,hnodes) * onodes^(-0.5);\n",
    "# There are various add-on packages in Julia that do random sampling from more complex distributions, but we leave that for some other time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "#training_data_file = open(\"mnist_dataset/mnist_train_100.csv\", 'r')\n",
    "training_data_file = open(\"mnist_dataset/mnist_train.csv\", \"r\")\n",
    "training_data_list = readlines(training_data_file)\n",
    "close(training_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train the neural network\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 5\n",
    "for e in 1:epochs\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list\n",
    "        # split the record by the ',' commas\n",
    "        interim = split(record, \",\")\n",
    "        # to convert the variable 'interim' into integers create an initial array (or length 785) and use a for loop to convert\n",
    "        all_values = Array(Int64, 785)\n",
    "        for i in 1:785\n",
    "            all_values[i] = parse(Float64, interim[i])\n",
    "        end\n",
    "        # scale and shift the inputs\n",
    "        inputs = all_values[2:end] / 255.0 * 0.99 + 0.01\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = zeros(output_nodes) + 0.01\n",
    "        # all_values[1] is the target label for this record\n",
    "        targets[all_values[1]+1] = 0.99\n",
    "        wih, who = train(wih, who, lr, inputs, targets)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "#training_data_file = open(\"mnist_dataset/mnist_train_100.csv\", 'r')\n",
    "test_data_file = open(\"mnist_dataset/mnist_test.csv\", \"r\")\n",
    "test_data_list = readlines(test_data_file)\n",
    "close(test_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test the neural network\n",
    "\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecard = []\n",
    "\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list\n",
    "    # split the record by the ',' commas\n",
    "    interim = split(record, ',')\n",
    "    all_values = Array(Int64, 785)\n",
    "    for i in 1:785\n",
    "        all_values[i] = parse(Float64, interim[i])\n",
    "    end\n",
    "    # correct answer is first value\n",
    "    correct_label = all_values[1]\n",
    "    # scale and shift the inputs\n",
    "    inputs = all_values[2:end] / 255.0 * 0.99 + 0.01\n",
    "    # query the network\n",
    "    outputs = query(wih, who, inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    # In Julia findmax returns two values; the maximum value and the first index of this maximum value\n",
    "    label = findmax(outputs)[2] - 1\n",
    "    # append correct or incorrect to list\n",
    "    # Julia does have an append command (thoug it has an eclamation mark at the end, e.g. append!(scorecard, 1)\n",
    "    # Another way of concatenation is to separate the elements using the semi-colon, as below.\n",
    "    if (label == correct_label)\n",
    "        # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard = [scorecard; 1];\n",
    "    else\n",
    "        # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard = [scorecard; 0];\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance = 0.9736\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score, the fraction of correct answers\n",
    "println(\"performance = \", sum(scorecard) / size(scorecard)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.5.1",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
